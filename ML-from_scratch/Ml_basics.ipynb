{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a11e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63342894",
   "metadata": {},
   "source": [
    "#  Softmax and Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257805c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "softmax = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39274880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msigmoid(inputs):\n",
    "    sig = 1 / (1 + torch.exp(-1*(inputs)))\n",
    "    return sig\n",
    "\n",
    "def msoftmax(inputs):\n",
    "    sof = torch.exp(inputs) / torch.exp(inputs).sum(1, keepdim=True)\n",
    "    return sof\n",
    "    \n",
    "def npsigmoid(inputs):\n",
    "    sig = 1 / (1 + np.exp(-1*(inputs)))\n",
    "    return sig\n",
    "\n",
    "def maxnpsoftmax(inputs):\n",
    "#     print(inputs.numpy())\n",
    "    X = np.exp(inputs.numpy() - np.max(inputs.numpy(), axis=-1, keepdims=True))\n",
    "    sof = X / X.sum(axis=-1, keepdims=True)\n",
    "    return sof\n",
    "\n",
    "def npsoftmax(inputs):\n",
    "#     print(inputs.numpy())\n",
    "    X = np.exp(inputs.numpy())\n",
    "    sof = X / X.sum(axis=-1, keepdims=True)\n",
    "    return sof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14b90ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 9],\n",
      "        [4, 2],\n",
      "        [7, 3],\n",
      "        [5, 9],\n",
      "        [1, 2],\n",
      "        [5, 2],\n",
      "        [5, 7],\n",
      "        [3, 4],\n",
      "        [9, 5],\n",
      "        [4, 3]])\n",
      "tensor([[0.0180, 0.9820],\n",
      "        [0.8808, 0.1192],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.0180, 0.9820],\n",
      "        [0.2689, 0.7311],\n",
      "        [0.9526, 0.0474],\n",
      "        [0.1192, 0.8808],\n",
      "        [0.2689, 0.7311],\n",
      "        [0.9820, 0.0180],\n",
      "        [0.7311, 0.2689]], dtype=torch.float64)\n",
      "[[0.01798621 0.98201379]\n",
      " [0.88079708 0.11920292]\n",
      " [0.98201379 0.01798621]\n",
      " [0.01798621 0.98201379]\n",
      " [0.26894142 0.73105858]\n",
      " [0.95257413 0.04742587]\n",
      " [0.11920292 0.88079708]\n",
      " [0.26894142 0.73105858]\n",
      " [0.98201379 0.01798621]\n",
      " [0.73105858 0.26894142]]\n",
      "[[0.01798621 0.98201379]\n",
      " [0.88079708 0.11920292]\n",
      " [0.98201379 0.01798621]\n",
      " [0.01798621 0.98201379]\n",
      " [0.26894142 0.73105858]\n",
      " [0.95257413 0.04742587]\n",
      " [0.11920292 0.88079708]\n",
      " [0.26894142 0.73105858]\n",
      " [0.98201379 0.01798621]\n",
      " [0.73105858 0.26894142]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-a49aab270035>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(softmax(torch.tensor(inputs, dtype=torch.float64)))\n",
      "<ipython-input-82-a49aab270035>:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  print(softmax(torch.tensor(inputs, dtype=torch.float64)))\n",
      "<ipython-input-82-a49aab270035>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(npsoftmax(torch.tensor(inputs, dtype=torch.float64)))\n",
      "<ipython-input-82-a49aab270035>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(maxnpsoftmax(torch.tensor(inputs, dtype=torch.float64)))\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randint(1,10,(10,2))\n",
    "# inputs = torch.randn(3)\n",
    "print(inputs)\n",
    "\n",
    "# print(sigmoid(inputs))\n",
    "# print(msigmoid(inputs))\n",
    "# print(npsigmoid(inputs.numpy()))\n",
    "\n",
    "\n",
    "print(softmax(torch.tensor(inputs, dtype=torch.float64)))\n",
    "# print(msoftmax(torch.tensor(inputs, dtype=torch.float64)))\n",
    "print(npsoftmax(torch.tensor(inputs, dtype=torch.float64)))\n",
    "print(maxnpsoftmax(torch.tensor(inputs, dtype=torch.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0e08aa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3], [1,1,1]]).sum(axis=(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mothership] *",
   "language": "python",
   "name": "conda-env-mothership-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
