{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb143e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c1b146f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]] [0 0 0] [0 1 2]\n",
      "100 100 [0 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_iris()\n",
    "\n",
    "data, label = dataset.data, dataset.target\n",
    "\n",
    "print(type(data), type(label))\n",
    "print(data[:3], label[:3], np.unique(label))\n",
    "\n",
    "data = data[label<2]\n",
    "label = label[label<2]\n",
    "\n",
    "print(len(data), len(label), np.unique(label))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24071fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "12e6fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5) (5,) (100,) (100,) (100,)\n",
      "loss for iter 0 is : 0.6931271807599428\n",
      "[ 0.         -1.26369942 -4.17581238  6.4249169   2.97745126]\n",
      "[1. 1.] [1 1]\n",
      "[ 0.         -1.26369942 -4.17581238  6.4249169   2.97745126]\n",
      "[1. 1.] [1 1]\n"
     ]
    }
   ],
   "source": [
    "# logistic regression for data, label \n",
    "import pickle\n",
    "\n",
    "\n",
    "class LogisticRegressionClassifier():\n",
    "\n",
    "    \n",
    "    def __init__(self, itr=100, lr=0.01, bias=True): \n",
    "        self.iter = itr\n",
    "        self.lr = lr \n",
    "        self.bias = bias\n",
    "        self.loss = []\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def load(model_path):\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "        return model\n",
    "   \n",
    "    def cross_entropy(self, y, h, gamma=0.00001):\n",
    "        return -np.sum(y*np.log(h + gamma) + (1-y)*np.log(1-h + gamma))/ len(self.X)\n",
    "        \n",
    "    \n",
    "    def sigmoid(self, h): \n",
    "        \n",
    "        return 1/(1 + np.exp(-h))\n",
    "    \n",
    "    def train(self, X, y): \n",
    "\n",
    "        if self.bias:\n",
    "            X = np.insert(X, 0, 0, axis=1)\n",
    "        self.X = X\n",
    "        weights = np.zeros(shape=X.shape[1])\n",
    "        \n",
    "        z = np.dot(X, weights)\n",
    "        h = self.sigmoid(z)\n",
    "        \n",
    "        print(X.shape, weights.shape, y.shape, z.shape, h.shape)\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            z = np.dot(X, weights)\n",
    "            h = self.sigmoid(z)\n",
    "            \n",
    "            derivative = np.dot(X.T ,h-y) \n",
    "            weights -= self.lr*derivative\n",
    "            \n",
    "            loss = self.cross_entropy(y,h)\n",
    "            self.loss.append(loss)\n",
    "#             print(weights)\n",
    "            if i%10000==0: \n",
    "                print(f\"loss for iter {i} is : {loss}\")\n",
    "\n",
    "        self.weights = weights\n",
    "            \n",
    "    def predict(self, x_test): \n",
    "        x_test = np.array(x_test)\n",
    "        z = np.dot(x_test, self.weights)\n",
    "        self.class_prob = self.sigmoid(z)\n",
    "        \n",
    "        self.labels = np.array([1 if x>0.5 else 0 for x in self.class_prob])\n",
    "        \n",
    "        return self.class_prob, self.labels\n",
    "        \n",
    "    \n",
    "    \n",
    "model = LogisticRegressionClassifier(itr=10000)\n",
    "model.train(data, label)\n",
    "\n",
    "print(model.weights)\n",
    "prob, labels = model.predict([[1,2,3,4,5], [2,3,4,5,6]])\n",
    "print(model.class_prob, model.labels)\n",
    "\n",
    "model.save('./test.pkl')\n",
    "\n",
    "model = LogisticRegressionClassifier.load('./test.pkl')\n",
    "\n",
    "print(model.weights)\n",
    "print(model.class_prob, model.labels)\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mothership] *",
   "language": "python",
   "name": "conda-env-mothership-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
